{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MLcmore2023/MLcmore2023/blob/main/day3_pm_afternoon/random-forest-demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Kt3W-oIPrK2"
      },
      "source": [
        "# Random Forest\n",
        "Random forest is an ensemble machine learning algorithm that combines multiple decision trees to make accurate classification and regression. It works by training numerous decision trees on different subsets of the dataset using bootstrapping (random sampling with replacement) and feature randomization. These trees collectively form a \"forest,\" and their predictions are averaged. Random forests are also non-parametric and require little to no parameter tuning. They differ from many common machine learning models used today that are typically optimized using gradient descent.\n",
        "\n",
        "<img src=\"https://www.tibco.com/sites/tibco/files/media_entity/2021-05/random-forest-diagram.svg\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# REVIEW: decision trees\n",
        "Random forest is made out of decision trees, so we will first review decision trees.\n",
        "<img src=\"https://raw.githubusercontent.com/MLcmore2023/MLcmore2023/main/.images/decisiontree1.png\" width=60%>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQB7oEzYgtEA"
      },
      "source": [
        "### Import libraries and initialize random generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oikAG7_2gub6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml # for loadin dataset\n",
        "# Set the seed value to make the random number reproducible\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5KlRlymhEh7"
      },
      "source": [
        "### Load data using `sklearn` library\n",
        "The sonar dataset contains data collected from sonar signals that were used to discriminate between underwater objects as either \"rocks\" or \"mines.\" The dataset consists of 208 observations, each represented by 60 features from sonar signals. The signals are obtained from a variety of different aspect angles. The goal is to classify these signals and distinguish between `rocks` and `mines`.\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/kaggle-datasets-images/1662635/2727659/3493b9309a1cf4f0c07aa6175b820060/dataset-card.jpg?t=2021-11-13-14-25-59\" width=20%>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz-PO04TWYIN",
        "outputId": "4cd570ff-269f-4598-abea-f33a25a7b0df"
      },
      "outputs": [],
      "source": [
        "# Load the Sonar dataset from scikit-learn's datasets\n",
        "sonar_data = fetch_openml(name='sonar', version=1, as_frame=True)\n",
        "\n",
        "# The dataset is loaded as a dictionary-like object\n",
        "X = sonar_data['data']    # Feature matrix\n",
        "y = sonar_data['target']  # Target values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "0ejNeK_QWYAI",
        "outputId": "fcb2a785-53a3-429d-bf73-f0168a176469"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attribute_1</th>\n",
              "      <th>attribute_2</th>\n",
              "      <th>attribute_3</th>\n",
              "      <th>attribute_4</th>\n",
              "      <th>attribute_5</th>\n",
              "      <th>attribute_6</th>\n",
              "      <th>attribute_7</th>\n",
              "      <th>attribute_8</th>\n",
              "      <th>attribute_9</th>\n",
              "      <th>attribute_10</th>\n",
              "      <th>...</th>\n",
              "      <th>attribute_51</th>\n",
              "      <th>attribute_52</th>\n",
              "      <th>attribute_53</th>\n",
              "      <th>attribute_54</th>\n",
              "      <th>attribute_55</th>\n",
              "      <th>attribute_56</th>\n",
              "      <th>attribute_57</th>\n",
              "      <th>attribute_58</th>\n",
              "      <th>attribute_59</th>\n",
              "      <th>attribute_60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0200</td>\n",
              "      <td>0.0371</td>\n",
              "      <td>0.0428</td>\n",
              "      <td>0.0207</td>\n",
              "      <td>0.0954</td>\n",
              "      <td>0.0986</td>\n",
              "      <td>0.1539</td>\n",
              "      <td>0.1601</td>\n",
              "      <td>0.3109</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0159</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0090</td>\n",
              "      <td>0.0032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>0.0187</td>\n",
              "      <td>0.0346</td>\n",
              "      <td>0.0168</td>\n",
              "      <td>0.0177</td>\n",
              "      <td>0.0393</td>\n",
              "      <td>0.1630</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.1694</td>\n",
              "      <td>0.2328</td>\n",
              "      <td>0.2684</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0116</td>\n",
              "      <td>0.0098</td>\n",
              "      <td>0.0199</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0065</td>\n",
              "      <td>0.0115</td>\n",
              "      <td>0.0193</td>\n",
              "      <td>0.0157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>0.0323</td>\n",
              "      <td>0.0101</td>\n",
              "      <td>0.0298</td>\n",
              "      <td>0.0564</td>\n",
              "      <td>0.0760</td>\n",
              "      <td>0.0958</td>\n",
              "      <td>0.0990</td>\n",
              "      <td>0.1018</td>\n",
              "      <td>0.1030</td>\n",
              "      <td>0.2154</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0093</td>\n",
              "      <td>0.0135</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>0.0063</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>0.0032</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0.0067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>0.0522</td>\n",
              "      <td>0.0437</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0292</td>\n",
              "      <td>0.0351</td>\n",
              "      <td>0.1171</td>\n",
              "      <td>0.1257</td>\n",
              "      <td>0.1178</td>\n",
              "      <td>0.1258</td>\n",
              "      <td>0.2529</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0155</td>\n",
              "      <td>0.0160</td>\n",
              "      <td>0.0029</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0138</td>\n",
              "      <td>0.0077</td>\n",
              "      <td>0.0031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>0.0303</td>\n",
              "      <td>0.0353</td>\n",
              "      <td>0.0490</td>\n",
              "      <td>0.0608</td>\n",
              "      <td>0.0167</td>\n",
              "      <td>0.1354</td>\n",
              "      <td>0.1465</td>\n",
              "      <td>0.1123</td>\n",
              "      <td>0.1945</td>\n",
              "      <td>0.2354</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0042</td>\n",
              "      <td>0.0086</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0126</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0035</td>\n",
              "      <td>0.0034</td>\n",
              "      <td>0.0079</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>0.0260</td>\n",
              "      <td>0.0363</td>\n",
              "      <td>0.0136</td>\n",
              "      <td>0.0272</td>\n",
              "      <td>0.0214</td>\n",
              "      <td>0.0338</td>\n",
              "      <td>0.0655</td>\n",
              "      <td>0.1400</td>\n",
              "      <td>0.1843</td>\n",
              "      <td>0.2354</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0181</td>\n",
              "      <td>0.0146</td>\n",
              "      <td>0.0129</td>\n",
              "      <td>0.0047</td>\n",
              "      <td>0.0039</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0115</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>208 rows Ã— 60 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     attribute_1  attribute_2  attribute_3  attribute_4  attribute_5  \\\n",
              "0         0.0200       0.0371       0.0428       0.0207       0.0954   \n",
              "1         0.0453       0.0523       0.0843       0.0689       0.1183   \n",
              "2         0.0262       0.0582       0.1099       0.1083       0.0974   \n",
              "3         0.0100       0.0171       0.0623       0.0205       0.0205   \n",
              "4         0.0762       0.0666       0.0481       0.0394       0.0590   \n",
              "..           ...          ...          ...          ...          ...   \n",
              "203       0.0187       0.0346       0.0168       0.0177       0.0393   \n",
              "204       0.0323       0.0101       0.0298       0.0564       0.0760   \n",
              "205       0.0522       0.0437       0.0180       0.0292       0.0351   \n",
              "206       0.0303       0.0353       0.0490       0.0608       0.0167   \n",
              "207       0.0260       0.0363       0.0136       0.0272       0.0214   \n",
              "\n",
              "     attribute_6  attribute_7  attribute_8  attribute_9  attribute_10  ...  \\\n",
              "0         0.0986       0.1539       0.1601       0.3109        0.2111  ...   \n",
              "1         0.2583       0.2156       0.3481       0.3337        0.2872  ...   \n",
              "2         0.2280       0.2431       0.3771       0.5598        0.6194  ...   \n",
              "3         0.0368       0.1098       0.1276       0.0598        0.1264  ...   \n",
              "4         0.0649       0.1209       0.2467       0.3564        0.4459  ...   \n",
              "..           ...          ...          ...          ...           ...  ...   \n",
              "203       0.1630       0.2028       0.1694       0.2328        0.2684  ...   \n",
              "204       0.0958       0.0990       0.1018       0.1030        0.2154  ...   \n",
              "205       0.1171       0.1257       0.1178       0.1258        0.2529  ...   \n",
              "206       0.1354       0.1465       0.1123       0.1945        0.2354  ...   \n",
              "207       0.0338       0.0655       0.1400       0.1843        0.2354  ...   \n",
              "\n",
              "     attribute_51  attribute_52  attribute_53  attribute_54  attribute_55  \\\n",
              "0          0.0232        0.0027        0.0065        0.0159        0.0072   \n",
              "1          0.0125        0.0084        0.0089        0.0048        0.0094   \n",
              "2          0.0033        0.0232        0.0166        0.0095        0.0180   \n",
              "3          0.0241        0.0121        0.0036        0.0150        0.0085   \n",
              "4          0.0156        0.0031        0.0054        0.0105        0.0110   \n",
              "..            ...           ...           ...           ...           ...   \n",
              "203        0.0203        0.0116        0.0098        0.0199        0.0033   \n",
              "204        0.0051        0.0061        0.0093        0.0135        0.0063   \n",
              "205        0.0155        0.0160        0.0029        0.0051        0.0062   \n",
              "206        0.0042        0.0086        0.0046        0.0126        0.0036   \n",
              "207        0.0181        0.0146        0.0129        0.0047        0.0039   \n",
              "\n",
              "     attribute_56  attribute_57  attribute_58  attribute_59  attribute_60  \n",
              "0          0.0167        0.0180        0.0084        0.0090        0.0032  \n",
              "1          0.0191        0.0140        0.0049        0.0052        0.0044  \n",
              "2          0.0244        0.0316        0.0164        0.0095        0.0078  \n",
              "3          0.0073        0.0050        0.0044        0.0040        0.0117  \n",
              "4          0.0015        0.0072        0.0048        0.0107        0.0094  \n",
              "..            ...           ...           ...           ...           ...  \n",
              "203        0.0101        0.0065        0.0115        0.0193        0.0157  \n",
              "204        0.0063        0.0034        0.0032        0.0062        0.0067  \n",
              "205        0.0089        0.0140        0.0138        0.0077        0.0031  \n",
              "206        0.0035        0.0034        0.0079        0.0036        0.0048  \n",
              "207        0.0061        0.0040        0.0036        0.0061        0.0115  \n",
              "\n",
              "[208 rows x 60 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lr4mwQaFWf9u",
        "outputId": "d23be017-9cfd-4fd0-c696-6a89cb07f9f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      Rock\n",
              "1      Rock\n",
              "2      Rock\n",
              "3      Rock\n",
              "4      Rock\n",
              "       ... \n",
              "203    Mine\n",
              "204    Mine\n",
              "205    Mine\n",
              "206    Mine\n",
              "207    Mine\n",
              "Name: Class, Length: 208, dtype: category\n",
              "Categories (2, object): ['Mine', 'Rock']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR5J0ok7h6Ew"
      },
      "source": [
        "There are two classes in our dataset: Rock and Mine. The labels are in strings, so we will convert these categorical labels from strings (e.g., \"Rock\" and \"Mine\") into 0 and 1. By converting strings to numbers, the models can process the data more efficiently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlTsxq8lW0in",
        "outputId": "7ff9969d-4143-40ea-e51c-a21f0922bcf2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "203    1\n",
              "204    1\n",
              "205    1\n",
              "206    1\n",
              "207    1\n",
              "Name: Class, Length: 208, dtype: category\n",
              "Categories (2, int64): [1, 0]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mapping = {\"Rock\": 0, \"Mine\": 1}\n",
        "\n",
        "# Use the map function to apply the mapping and convert strings to integers\n",
        "y = y.map(mapping)\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFmKw2T5inX7"
      },
      "source": [
        "we now convert the dataset into numpy arrays so later we can perform calculations on them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6rPUtqjhWgfT"
      },
      "outputs": [],
      "source": [
        "X = X.to_numpy()\n",
        "y = y.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wt7L_g5jC_t"
      },
      "source": [
        "### Split the dataset into training sets and testing sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TNaA53YYXZxM"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iha0UYkJAMOv"
      },
      "source": [
        "We will use `sklearn` library's decision tree to make predictions on the sonar dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5dBGIjbXk5V",
        "outputId": "0a4a58e4-b57e-43a6-bebd-643562021248"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 1 0 1 1 0 1 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 0 1 1 0 1 1 1\n",
            " 1 0 1 1 0]\n",
            "[1 1 1 0 1 1 1 1 1 0 0 1 0 1 0 0 1 0 0 0 0 1 1 1 0 1 0 1 1 1 0 0 1 0 1 1 1\n",
            " 1 1 1 1 0]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create and train the Decision Tree model\n",
        "decision_tree = DecisionTreeClassifier(max_depth=None)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = decision_tree.predict(X_test)\n",
        "\n",
        "# See result\n",
        "print(y_test)\n",
        "print(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCljytroAkgI"
      },
      "source": [
        "a big problem with decision tree is that they are not accurate on complicated datasets. We can see that the prediction is very different than the actual y. The accuracy is very low."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HskDkHffYE4F",
        "outputId": "74814f0f-b08c-42bc-f6a2-d3b0fd2eb2f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[False False False  True  True False  True  True False False  True  True\n",
            "  True  True  True  True  True  True  True  True False False False False\n",
            "  True  True False  True  True  True  True False  True  True  True  True\n",
            "  True  True False  True  True  True]\n"
          ]
        }
      ],
      "source": [
        "print(y_test==predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kUK-lnSjO30",
        "outputId": "340a5dfc-7c56-43ce-e8cd-a9d73503f25a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6904761904761905\n"
          ]
        }
      ],
      "source": [
        "N = len(y_test)\n",
        "count_of_correct_predictions = sum( y_test==predictions  )\n",
        "accuracy = count_of_correct_predictions/N\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHhi3uZykmod"
      },
      "source": [
        "### Initialize model\n",
        "Decision trees are easy to make and easy to interpret. However, in the real world, they are usually NOT accuracy on complex dataset. Random forest solve this problem by have many decision trees, and combining the result.\n",
        "\n",
        "Therefore, in random forest, the model is simply a list of individual decision trees.\n",
        "` [ðŸŒ³0, ðŸŒ³1, ðŸŒ³2, ðŸŒ³3... ]`\n",
        "\n",
        "To initialize the model, we just make an empty list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Xv1HXgAhko6B"
      },
      "outputs": [],
      "source": [
        "random_forest_model = [] # empty list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NfpOE7WmjMo"
      },
      "source": [
        "### Bootstrapping\n",
        "One of the main reasons random forests are a powerul machine learning model is the idea behind injecting randomness into each tree. Each individual decision tree will be constructed on a \"bootstrapped\" subset of our data. If our dataset has $n$ observations \"bootstrapping\" is the process of sampling $n$ points **with** replacement. The probability an observation is omitted from our bootstrapped dataset is  $(1 - \\frac{1}{n})^{n}$. $e^{-1} = \\displaystyle \\lim_{n\\to\\infty}(1-\\frac{1}{n})^n$ and since $e^{-1}$ = 0.36787.. $\\approx \\frac{1}{3}$ $\\Rightarrow$ bootstrapping $n$ samples with replacement will leave out approximately $\\frac{1}{3}$ of the observations in each distinct tree. Since each individual tree is built using only $\\frac{2}{3}$ of the data, each tree will be different from each other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vvwj0Cgzrerz"
      },
      "outputs": [],
      "source": [
        "example_list = np.array(['a','b','c','d','e','f','g','h'])\n",
        "N = 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQBQEnlvrsYA",
        "outputId": "d99cb45a-2de9-410e-f2e1-53e1d65a21c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 2 3 3 4 5 7]\n"
          ]
        }
      ],
      "source": [
        "bootstrap_indices = np.random.choice(N, N, replace=True)\n",
        "bootstrap_indices.sort() # sort the array so it is easier for us to read (this is not necessary)\n",
        "print(bootstrap_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 267,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDSloe7Wr1k1",
        "outputId": "f3b5f184-76b1-4a81-ded1-c977e40a00b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['a' 'a' 'c' 'd' 'd' 'e' 'f' 'h']\n"
          ]
        }
      ],
      "source": [
        "bootstrap_sample = example_list[bootstrap_indices]\n",
        "print(bootstrap_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "cY10KapcnqDj"
      },
      "outputs": [],
      "source": [
        "def bootstrap_sampling(X, y):\n",
        "    N = X.shape[0] # how many entries are there in the dataset\n",
        "    bootstrap_indices = np.random.choice(N, N, replace=True)\n",
        "\n",
        "    X_bootstrap = X[bootstrap_indices]\n",
        "    y_bootstrap = y[bootstrap_indices]\n",
        "\n",
        "    return X_bootstrap, y_bootstrap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcuDAEtuR62l"
      },
      "source": [
        "### Making a random forest\n",
        "There are 3 steps:\n",
        "1. Decide how many trees we want. We will use 100 for here.\n",
        "2. For every tree, first make a bootstrap sample from the data\n",
        "3. Make the decision tree and append it to the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "z9ohDn64RnXT"
      },
      "outputs": [],
      "source": [
        "n_estimators = 100 # The number of trees in the forest\n",
        "\n",
        "def train_random_forest(X, y, random_forest_model):\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    for i in range(n_estimators):\n",
        "        # Bootstrap sampling\n",
        "        X_bootstrap, y_bootstrap = bootstrap_sampling(X,y)\n",
        "\n",
        "        # Create a Decision Tree and fit it to the bootstrap sample\n",
        "        tree = DecisionTreeClassifier(max_depth=50, max_features=100)\n",
        "        tree.fit(X_bootstrap, y_bootstrap)\n",
        "\n",
        "        # Append the trained Decision Tree to the list of estimators\n",
        "        random_forest_model.append(tree)\n",
        "\n",
        "# Create and train the Random Forest model\n",
        "train_random_forest(X_train, y_train, random_forest_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZVLhQQcSPcs"
      },
      "source": [
        "### Making predictions\n",
        "A Random Forest predicts by getting individual predictions from all trees, and then it chooses the answer that most trees agree on for classification. This teamwork helps make better predictions and avoids mistakes from just one tree.\n",
        "\n",
        "Below shows code that is NOT simplified, because later in the exercise you (students) will make a `predict_1_sample` function yourself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HSBc2mHQOtu7"
      },
      "outputs": [],
      "source": [
        "def predict(X, random_forest_model):\n",
        "    # this code is obfuscated. You will implement this function again in later exercise\n",
        "    return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=np.array([tree.predict(X) for tree in random_forest_model]))\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = predict(X_test, random_forest_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDg2M9-jS2_J"
      },
      "source": [
        "### Evaluate accuracy\n",
        "We can see that the resulting accuracy is now much higher than before, when we just used a single decision tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7bxJ_zLesRC",
        "outputId": "a7f87d2a-5380-4435-9a72-80197d89e6ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ True False False  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True False  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True False  True  True  True]\n",
            "0.8809523809523809\n"
          ]
        }
      ],
      "source": [
        "print(y_test==predictions)\n",
        "\n",
        "N = len(y_test)\n",
        "count_of_correct_predictions = sum( y_test==predictions  )\n",
        "accuracy = count_of_correct_predictions/N\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRS3bIS9TQi0"
      },
      "source": [
        "### Exercise\n",
        "1. In our random forest, we have 100 decision trees. Are these 100 trees the same or different from each other? Why?\n",
        "2. Is it possible that our 100 decision trees all give the same result for a prediction? Why?\n",
        "3. Is it possible that our 100 decision trees give different results for a prediction? Why?\n",
        "4. In this case, what should our code do?\n",
        "5. Make a `predict_1_sample` function, which takes in 1 sonar data `x` and returns the prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdD5l49EWXKE"
      },
      "outputs": [],
      "source": [
        "def predict_1_sample(x, random_forest_model):\n",
        "    # exercise code goes here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "Ms4MP06IWbBo",
        "outputId": "7c04c05e-289e-4c90-90ae-b6a983e6664c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0]\n",
            "[ True False False  True  True  True  True  True  True False  True  True\n",
            "  True  True  True  True  True  True  True  True  True  True False  True\n",
            "  True  True  True  True  True  True  True  True  True  True  True  True\n",
            "  True  True False  True  True  True]\n",
            "0.8809523809523809\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test set\n",
        "predictions = []\n",
        "for x in X_test:\n",
        "  p = predict_1_sample(x, random_forest_model)\n",
        "  predictions.append(p)\n",
        "print(predictions)\n",
        "print(predictions == y_test)\n",
        "\n",
        "N = len(y_test)\n",
        "count_of_correct_predictions = sum( y_test==predictions  )\n",
        "accuracy = count_of_correct_predictions/N\n",
        "print(accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "_cell_guid": "86b72524-a190-4b9a-80ea-81fb96f60843",
        "_uuid": "e2b0fb51-dcb5-43bb-a15e-415a28891a19",
        "id": "z9CYqMR0PqJP",
        "trusted": true
      },
      "source": [
        "## References\n",
        "- L. Breiman. Random forests. Maching Learning, 45(1):5â€“32, Oct. 2001. [[pdf]](https://link.springer.com/content/pdf/10.1023%2FA%3A1010933404324.pdf)\n",
        "- https://carbonati.github.io/posts/random-forests-from-scratch/\n",
        "- https://www.tibco.com/reference-center/what-is-a-random-forest\n",
        "- https://www.youtube.com/watch?v=J4Wdy0Wc_xQ"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
